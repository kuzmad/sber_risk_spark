{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHgYpJXKoPIi",
    "outputId": "7f6d219e-4138-4bc4-fef4-bac34895b1af"
   },
   "outputs": [],
   "source": [
    "!pip install pyspark findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUBraSjDoaDp"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().set('spark.ui.port', '4050').set('spark.serializer', 'org.apache.spark.serializer.KryoSerializer')\\\n",
    "                  .set('spark.dynamicAllocation.enabled', 'true')\\\n",
    "                  .set('spark.shuffle.service.enabled', 'true') #трекер, чтобы возвращать ресурсы\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdchPhE6osBh"
   },
   "source": [
    "**Создание DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuQZiqE8pLBg"
   },
   "source": [
    "Из RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0HRKDcbpeT1"
   },
   "outputs": [],
   "source": [
    "def cleaning(row):\n",
    "    row = row.split('\\t')[:3]\n",
    "    row = [float(val) for val in row]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83oW4J6ioqwt"
   },
   "outputs": [],
   "source": [
    "ratings = sc.textFile('user_ratedmovies.dat')\n",
    "\n",
    "first_row = ratings.first()\n",
    "ratings = ratings.filter(lambda row: row != first_row)\\\n",
    "                 .map(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs-On6Warlgm"
   },
   "outputs": [],
   "source": [
    "columns = first_row.split('\\t')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3JWv9Cdr1y7",
    "outputId": "0861dfe0-26ff-4c83-b7b5-d9b7eeb13768"
   },
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HHFa4NOpl8U",
    "outputId": "b426aef3-01de-4bd5-994f-b53b0f8a6185"
   },
   "outputs": [],
   "source": [
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6EbyjOzp2Rz"
   },
   "outputs": [],
   "source": [
    "df_rdd = spark.createDataFrame(ratings, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grAj61Pqqcot",
    "outputId": "f54e54d8-a876-4f39-ae65-e8ae2cde473c"
   },
   "outputs": [],
   "source": [
    "df_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGdP3oErrBn2"
   },
   "source": [
    "Можно еще вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm2IjgCKrGQR"
   },
   "outputs": [],
   "source": [
    "df_rdd = ratings.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNeXMPNQsLV1",
    "outputId": "a77e820a-ac8f-4a08-a94f-ccc33030a015"
   },
   "outputs": [],
   "source": [
    "df_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cHlkz0Rsf2W"
   },
   "source": [
    "Так, а если не хочу вот эти приседания с RDD, а хочу сразу из файла?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFkXM_vZu_1t"
   },
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "          .format(\"csv\")\\\n",
    "          .options(**{'sep': '\\t', 'header': 'true'})\\\n",
    "          .load(\"user_ratedmovies.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlZNFbmpvQKN",
    "outputId": "3d0c18fd-9621-404e-ad12-82dc1dd80295"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2tEvxnrxka6"
   },
   "source": [
    "Все в string, так не пойдет, давайте автоматически определим тип данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTXHlh2msvaY"
   },
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "          .format(\"csv\")\\\n",
    "          .options(**{'sep': '\\t', 'header': 'true', 'inferSchema': 'true'})\\\n",
    "          .load(\"user_ratedmovies.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84-8zIkJzgGC",
    "outputId": "864994bc-b4ed-4990-86c0-48605aa83e9c"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJcH3xqwz5JC",
    "outputId": "9c805923-6abd-4e4a-e7b5-cddce5f71eaa"
   },
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65EYIo0O1v2s"
   },
   "source": [
    "А можно заранее сказать, какой тип данных я ожидаю?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBTjPC1-102G"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axRDyclD3YZX"
   },
   "outputs": [],
   "source": [
    "schema = StructType([ \\\n",
    "    StructField(\"userID\",IntegerType(),True), \\\n",
    "    StructField(\"movieID\",IntegerType(),True), \\\n",
    "    StructField(\"rating\",DoubleType(),True), \\\n",
    "    StructField(\"date_day\", StringType(), True), \\\n",
    "    StructField(\"date_month\", StringType(), True), \\\n",
    "    StructField(\"date_year\", IntegerType(), True), \\\n",
    "    StructField(\"date_hour\", IntegerType(), True), \\\n",
    "    StructField(\"date_minute\", IntegerType(), True), \\\n",
    "    StructField(\"date_second\", IntegerType(), True)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y16zNsdF4GdA"
   },
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "          .format(\"csv\")\\\n",
    "          .options(**{'sep': '\\t', 'header': 'true'})\\\n",
    "          .schema(schema)\\\n",
    "          .load(\"user_ratedmovies.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyZqtXpN4Teq",
    "outputId": "f58a78e0-2d88-49e1-d0a7-5512af2990bb"
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7hegloJ4W0j",
    "outputId": "22b8fcf7-7d3d-4142-fa5d-b26dad2abd2f"
   },
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdxJ2Mts42yh"
   },
   "source": [
    "Но есть уже готовая обертка под все нужды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Z3BQYgq46H2"
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(path='user_ratedmovies.dat', sep='\\t', header=True, inferSchema=True, schema=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_QGJgItBcr5",
    "outputId": "25b4b40d-2ca4-4f44-b6c3-4277ffe520f2"
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AikPkbuN44v"
   },
   "source": [
    "Так, а как сохранить? Лучше быть аккуратнее с overwrite, перезапишет весь указанный путь, append будет безопаснее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvoejV_lN7Wx"
   },
   "outputs": [],
   "source": [
    "df.write.option(\"header\",True)\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .parquet('write_1.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9FAZTtsOU_D"
   },
   "source": [
    "А что с партицированием?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5DXXgA5OUJL"
   },
   "outputs": [],
   "source": [
    "df.write.option(\"header\",True)\\\n",
    "        .partitionBy('date_year')\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .parquet('write_2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVWgHcej7BW8"
   },
   "source": [
    "Кстати, раз уж заговорили про схемы данных, то из можно задвать интереснее, например, под группированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGlOCL_f7K6S",
    "outputId": "a02cd333-c628-4438-974f-dfc4560dba44"
   },
   "outputs": [],
   "source": [
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iClIlEKr8iTj"
   },
   "source": [
    "Со структурой можно работать и менять ее под ваши нужны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vm4_WIJS8dgO",
    "outputId": "8c2a7fe4-db76-4dc2-aa9e-72eb69d11966"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,struct,when\n",
    "updatedDF = df2.withColumn(\"OtherInfo\", \n",
    "    struct(col(\"id\").alias(\"identifier\"),\n",
    "    col(\"gender\").alias(\"gender\"),\n",
    "    col(\"salary\").alias(\"salary\"),\n",
    "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
    "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
    "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "  )).drop(\"id\",\"gender\",\"salary\")\n",
    "\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0ahr4fX9Upl"
   },
   "source": [
    "Что мы там сделали????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LDl88xh9ijH"
   },
   "source": [
    "1) Создали новую структуру данных OtherInfo\n",
    "\n",
    "2) Передали туда id (переименовав столбец), gender, salary\n",
    "\n",
    "3) Создали столбец Salary_grade из условий\n",
    "\n",
    "4) удалили id, gender, salary из старой структуры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCQAE9lcB9t0"
   },
   "source": [
    "Есть и еще структуры данных!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mubsrdL7CECm"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmTN8aYYCLaP"
   },
   "outputs": [],
   "source": [
    "arrayStructureSchema = StructType([\n",
    "    StructField('name', StructType([\n",
    "       StructField('firstname', StringType(), True),\n",
    "       StructField('middlename', StringType(), True),\n",
    "       StructField('lastname', StringType(), True)\n",
    "       ])),\n",
    "       StructField('hobbies', ArrayType(StringType()), True),\n",
    "       StructField('properties', MapType(IntegerType(),StringType()), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yD1B3QxQCk2f"
   },
   "outputs": [],
   "source": [
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"), ['car', 'volleyball'], {1: 'a', 4: 'd'}),\n",
    "    ((\"Michael\",\"Rose\",\"\"), ['car', 'football'], {2: 'b'}),\n",
    "    ((\"Robert\",\"\",\"Williams\"), ['box', 'music'], {3: 'c'})\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ALozaKICfMB",
    "outputId": "d2315ee3-c94a-42a6-fac3-5fb321cc398d"
   },
   "outputs": [],
   "source": [
    "df3 = spark.createDataFrame(data=structureData,schema=arrayStructureSchema)\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLbNPk3YDiOY",
    "outputId": "47f2fa99-6c87-4c1e-83fb-4496c3f26f31"
   },
   "outputs": [],
   "source": [
    "df3.select('properties').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uQ1cQpyCF_X"
   },
   "source": [
    "**Описание данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUn_TbKyCGCQ"
   },
   "source": [
    "Общее описание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFT3OfOsFTl4"
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(path='user_ratedmovies.dat', sep='\\t', header=True, inferSchema=True, schema=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xsYm_0aCANH",
    "outputId": "0d53ec2e-6ab5-4882-85dc-ea2ba25471a8"
   },
   "outputs": [],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzoQTDS1CZdC",
    "outputId": "6ab0f09e-df64-4ede-8142-bd7851d0777c"
   },
   "outputs": [],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTWN1cf_CrOT"
   },
   "source": [
    "Количество записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVITW7_FCg7X",
    "outputId": "a3a09848-0c50-4c05-9de7-8fdb1540e27a"
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gei1DA_MDXEM"
   },
   "source": [
    "Количество партиций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LxCM_uMCoOQ",
    "outputId": "4c8e3b8d-24ac-4567-f5a0-e0c9d6e91191"
   },
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uARz4b3lDdVF"
   },
   "source": [
    " Менять число партиций можно, все как с rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76UNLPKHDosI"
   },
   "outputs": [],
   "source": [
    "df = df.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdVfa-ODDtXz",
    "outputId": "fbaf7d88-8ef0-4202-c59c-61b0fb424ae7"
   },
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIDPMK-qDv7p"
   },
   "outputs": [],
   "source": [
    "df = df.coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hsG5g_aLDyPg",
    "outputId": "1a307d7c-f35e-4085-d6b5-13626c9e25e6"
   },
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R30yappBElPl"
   },
   "source": [
    "**Различные методы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTysHYCwEMQb"
   },
   "source": [
    "Ну теперь давайте тыкать "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-t0HREvEuXf"
   },
   "source": [
    "Удаляем дубликаты и помним, что есть actions и transformations, count заставит все сделать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grCgDf3XEJAG"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFX2rl8lFFNg"
   },
   "source": [
    "Есть alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hXkMPVWFD0D"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdTTlyDXFVgV"
   },
   "source": [
    "Как удалить дубликаты по отдельным колонкам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WSm1GHBFK1Y"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates = df.drop_duplicates(['userID', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UDcQusBF0MU",
    "outputId": "63fbcc5d-df15-4a7b-e2da-61ef58319212"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uu6IuhVlGAJ8",
    "outputId": "6d29fca0-ac1b-4f8d-a347-7e555c7f12e1"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xLCdjnxQf-k"
   },
   "source": [
    "Корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_px4MeZ_QbWw",
    "outputId": "bc756a27-dcc8-46bb-97cb-fdfcfd9e162a"
   },
   "outputs": [],
   "source": [
    "df.corr('rating', 'date_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojnd-9aoQp-z",
    "outputId": "10740a87-1f45-4c5a-cc15-a536f9cb1efb"
   },
   "outputs": [],
   "source": [
    "df.corr('rating', 'date_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1yF8JE2QxCb",
    "outputId": "14376fd3-84a5-4a7e-c501-1d387306cabe"
   },
   "outputs": [],
   "source": [
    "df.corr('rating', 'date_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EuaTuZHwbKI"
   },
   "source": [
    "Как закинуть данные в любимый pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYMdZ4UIwius"
   },
   "source": [
    " Самый простой вариант - встроенный метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2K09OLKzoI1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koXxQVt_wh82"
   },
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "N4IMwKC1wsvH",
    "outputId": "dc68fd72-28bc-4a85-8558-9af138f6f6b9"
   },
   "outputs": [],
   "source": [
    "pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGsLsipKxqQx"
   },
   "source": [
    "Как говорили на лекции, может все упасть например тут. Как перейти к итератору?\n",
    "\n",
    "prefetchPartitions - подготавливать ли следующую партию данных, пока не запросили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ys7zOtU2xx99"
   },
   "outputs": [],
   "source": [
    "iter_df = df.toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBjM9GcryjUQ"
   },
   "outputs": [],
   "source": [
    "row = iter_df.send(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IxLtM7YzLC3",
    "outputId": "0e506090-2e7b-4312-f7d0-461dbc289f03"
   },
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kdzog3jYv-nT",
    "outputId": "4f5a2cdf-a13e-42ac-d460-9d27e2e3e6ad"
   },
   "outputs": [],
   "source": [
    "row.asDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLMHUi8ozQl5"
   },
   "source": [
    "Отсюда идея: можно вытягивать данные по 1 записи и записывать в датафрейм. Долго, но зато отработает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNvszzqvzhON"
   },
   "outputs": [],
   "source": [
    "iter_df = df.toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogfT_1dv0FbK",
    "outputId": "7b856d9d-b1e0-44b9-8072-555bc7abfe89"
   },
   "outputs": [],
   "source": [
    "list_of_rows = [value for value in iter_df]\n",
    "print(len(list_of_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tg3u4mWo0m2x",
    "outputId": "5b7dc053-f5df-4cd7-8517-66c4d8c6612f"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehao9C3m0bSf"
   },
   "outputs": [],
   "source": [
    "pandas_df = pd.DataFrame(list_of_rows, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "KKr_PXmO0hK1",
    "outputId": "7f164619-bca8-4b13-a3f3-3b131c00b210"
   },
   "outputs": [],
   "source": [
    "pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyNzrNDW3FI4"
   },
   "source": [
    "**Show**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYNJKbQJ2up1",
    "outputId": "7b548241-889f-4c23-9950-b72285e1de7c"
   },
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ymp1StL3aFi"
   },
   "source": [
    "Обрезаем до 2 символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFXsxrXH3NQS",
    "outputId": "26d27a3b-b431-45d6-a98e-530e699f0571"
   },
   "outputs": [],
   "source": [
    "df.show(10, truncate=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMoppJfS3klG"
   },
   "source": [
    "вертикальное отображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCuKzAS83dM4",
    "outputId": "cf89a57b-0cf2-42ef-95e3-8b33c61f5f5a"
   },
   "outputs": [],
   "source": [
    "df.show(10, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVFKxBsuFU5i"
   },
   "source": [
    "**Select**\n",
    "\n",
    "В PySpark функция select() используется для выбора одного, нескольких столбцов по индексу, всех столбцов из списка и вложенных столбцов из фрейма данных. Функция PySpark select() является функцией преобразования, поэтому она возвращает новый фрейм данных с выбранными столбцами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dliaTxGxFnzr",
    "outputId": "8e446696-cfcb-4cf6-868f-490f3b901c13"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cInhSbcBGtKn"
   },
   "source": [
    "Упс, pandas-style тут не приветствуется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "Ms8Gqj0WGpOJ",
    "outputId": "2384cb05-89cd-4471-8d70-7e4cf3402037"
   },
   "outputs": [],
   "source": [
    "df.userID.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSF9GuB6Fwv7",
    "outputId": "2f02e5a6-1530-4250-f7e3-4b22f9c66042"
   },
   "outputs": [],
   "source": [
    "df.select('userID').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8s0NRdtGHcZ"
   },
   "source": [
    "Куча вариантов, выбирайте любой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sUEL7yHF4mA",
    "outputId": "44361f07-192a-4636-a344-346872a09543"
   },
   "outputs": [],
   "source": [
    "df.select('userID', 'rating').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KynOoDxUF-DU",
    "outputId": "0d92dabc-f7ac-4e58-d030-0104e3ca00dc"
   },
   "outputs": [],
   "source": [
    "df.select(['userID', 'rating']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZrRyJPLGcHU",
    "outputId": "d864c03c-3007-413d-b3b6-2208d7136db6"
   },
   "outputs": [],
   "source": [
    "df.select(df.userID,df.rating).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNkrq1TUGwSb",
    "outputId": "922e30ef-b551-44a5-f7fb-5f5f23aafacb"
   },
   "outputs": [],
   "source": [
    "df.select(df['userID'],df['rating']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "La3Q3k01GZ3-",
    "outputId": "99e55327-1cea-47c1-ec9c-4d88d8abb1fd"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"userID\"),col(\"rating\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Pfledp7JxFo"
   },
   "source": [
    "можно налету переименовать столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23c1EFh0JgCm",
    "outputId": "32524014-a769-4712-cf1d-a5ab3fd63472"
   },
   "outputs": [],
   "source": [
    "df.select(df.userID, df.rating.alias('mark')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-15TG7h8G-7L",
    "outputId": "2e8450c7-e266-4bd5-fba5-5830d41ac58b"
   },
   "outputs": [],
   "source": [
    "#регулярки\n",
    "df.select(df.colRegex(\"`d+.*y`\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zRsPk3PItus"
   },
   "source": [
    "примеры с дургим датафреймом, где структура сложнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-EHUbgMJATb",
    "outputId": "64943332-ca03-440a-b18e-ac21b098cb9a"
   },
   "outputs": [],
   "source": [
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOKRrq3OJBub",
    "outputId": "9f2d4168-fed8-409d-e26a-e7fac049a034"
   },
   "outputs": [],
   "source": [
    "df2.select('name').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7wWDSc0JGGH",
    "outputId": "ff4a7520-f5f3-4982-a7a7-52c815e62964"
   },
   "outputs": [],
   "source": [
    "df2.select('name.lastname').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCtpj47VJLhf",
    "outputId": "9c8a7b15-7610-4d25-e6c6-1dcfdb9155b2"
   },
   "outputs": [],
   "source": [
    "df2.select('name.firstname', 'name.lastname').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnz1-TbQVWhF"
   },
   "source": [
    "**withColumn**\n",
    "\n",
    "PySpark withColumn() - это функция преобразования (transform), которая используется для изменения значения, преобразования типа данных существующего столбца, создания нового столбца и многого другого. Поговорим о часто используемых операциях со столбцами данных PySpark, используя примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUhukrY0Y0Q2",
    "outputId": "9f71e0ad-10a5-4d2f-f8c8-9bf64f7fbbbc"
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4biHC1yYv7w"
   },
   "source": [
    "Меняем тип данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGHnOBJ1YrGA",
    "outputId": "36c8532a-5c9b-4563-9122-530696632d1d"
   },
   "outputs": [],
   "source": [
    "df.withColumn(\"date_month\",col(\"date_month\").cast(\"String\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlM-ozjcZaJT"
   },
   "source": [
    "Модифицировать столбец/создать новый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6afdpcQrZMWX",
    "outputId": "7384b099-f42c-4e64-c03d-283c145103a8"
   },
   "outputs": [],
   "source": [
    "df.withColumn(\"rating_x_10\",col(\"rating\") * 10).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSFyjtL6Z_WT"
   },
   "source": [
    "Делаем 2 константных столбца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K__QFfDqaCeU"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tjCFJKAaLnO",
    "outputId": "c327fc3f-d122-402b-daa2-1c1d8cde67bd"
   },
   "outputs": [],
   "source": [
    "df.withColumn('fix_1', lit(1)).withColumn('fix_2', lit(2)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq7AyqA7ajCw"
   },
   "source": [
    "**withColumnsRenamed**\n",
    "\n",
    "Предыдущий вариант не давал возможности переименовать столбцы, это можно сделать иначе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhNQL1UaaoWn",
    "outputId": "52a86ca7-dbe5-4083-fbfd-4b50c871f67d"
   },
   "outputs": [],
   "source": [
    "df.withColumnRenamed('rating', 'mark').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7XsfsdNbq_M"
   },
   "source": [
    "**filter (where) и иные филтрации**\n",
    "\n",
    "Функция PySpark filter() используется для фильтрации строк из RDD / DataFrame на основе заданного условия или выражения SQL, вы также можете использовать предложение where() вместо filter() обе эти функции работают аналогично."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVbRAIZ-eWm3"
   },
   "source": [
    "1 условие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFzp724CddPb",
    "outputId": "70dd34c0-50f6-479a-e36e-d9f7587bc062"
   },
   "outputs": [],
   "source": [
    "df.filter(df.rating == 5.0).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHYMQDRveND2",
    "outputId": "83dbb610-d1e0-45e5-b713-fd0a93e3b10e"
   },
   "outputs": [],
   "source": [
    "df.filter(~(df.rating == 5.0)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VF0jZSiFeRvT",
    "outputId": "6f05411a-ea9a-419f-b92f-347398c5ee70"
   },
   "outputs": [],
   "source": [
    "df.filter('rating = 5').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-tzppVSehGc"
   },
   "source": [
    "Несколько условий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RG2nk91dekM_",
    "outputId": "b5733ac1-28fe-451e-f2ce-e3ebc9b27fb2"
   },
   "outputs": [],
   "source": [
    "df.filter((df.rating == 5.0) & (df.date_year == 2006)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXGvcpqdfRK-",
    "outputId": "8e2bc8ab-bd3d-4528-9020-b6f413b3dde7"
   },
   "outputs": [],
   "source": [
    "df.filter('(rating = 5.0) and (date_year = 2006)').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPJrcN3Zh5zu",
    "outputId": "b40f86e2-fee1-4d24-b154-d305cf13f058"
   },
   "outputs": [],
   "source": [
    "df.filter('(rating = 5.0) and (userID between 70 and 80)').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdE18CsVfepu"
   },
   "source": [
    "фильтр по списку значений из list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHYaVt1Sfix6"
   },
   "outputs": [],
   "source": [
    "years = [2006, 2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtScT6Ljf1f0",
    "outputId": "2b15019d-c911-4668-abad-b64bdbf5308d"
   },
   "outputs": [],
   "source": [
    "df.filter(df.date_year.isin(years)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8xkT6PxgJXy"
   },
   "source": [
    " проверим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpQJJAchf-aY",
    "outputId": "a20b55b7-731d-4822-8631-03d302681e9f"
   },
   "outputs": [],
   "source": [
    "df.filter(df.date_year.isin(years))\\\n",
    "  .select('date_year')\\\n",
    "  .dropDuplicates()\\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baQHzWATiWPQ"
   },
   "source": [
    "создадим игрушечный датайфрейм для текстовых столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j25PuaiOiVs0"
   },
   "outputs": [],
   "source": [
    "data2 = [(2,\"Michael Rose\"),(3,\"Robert Williams\"),\n",
    "     (4,\"Rames Rose\"),(5,\"Rames Black\"), (6, 'Albus Torch'),\n",
    "     (7, 'Fred Tf')\n",
    "  ]\n",
    "df2 = spark.createDataFrame(data2, ['id', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_3UfWtuisqY",
    "outputId": "44c6ce25-2400-479b-ea4d-3a413e0ab5ff"
   },
   "outputs": [],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfIw-U8pilfQ",
    "outputId": "98c512b9-2948-4eff-9773-dc70a197914c"
   },
   "outputs": [],
   "source": [
    "df2.filter('name like \"R%\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_9M2YTCjpGf",
    "outputId": "a349d1fd-d7b1-4a77-b866-ee07226904e4"
   },
   "outputs": [],
   "source": [
    "df2.filter(df2.name.startswith('R')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qd6XuQbj1ca",
    "outputId": "83edc985-8ba1-42a9-ac83-be96d5e4ab5d"
   },
   "outputs": [],
   "source": [
    "df2.filter(df2.name.endswith('Tf')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPWVmWSFj5rA",
    "outputId": "ee15d59d-1688-436f-c78a-a65f2d126c52"
   },
   "outputs": [],
   "source": [
    "df2.filter(df2.name.contains('Wil')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfgGaL_zkIiF"
   },
   "source": [
    "Бывает, что у нас внутри датафрейма есть массив и с ним что-то хочется сделать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b3himCXj98O"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTpNzm_Lkl5d",
    "outputId": "577b9fc5-1c8b-4e78-e85f-aed4a7d69868"
   },
   "outputs": [],
   "source": [
    "arrayStructureSchema = StructType([\n",
    "    StructField('name', StructType([\n",
    "       StructField('firstname', StringType(), True),\n",
    "       StructField('middlename', StringType(), True),\n",
    "       StructField('lastname', StringType(), True)\n",
    "       ])),\n",
    "       StructField('hobbies', ArrayType(StringType()), True),\n",
    "       StructField('properties', MapType(IntegerType(),StringType()), True)\n",
    "    ])\n",
    "\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"), ['car', 'volleyball'], {1: 'a', 4: 'd'}),\n",
    "    ((\"Michael\",\"Rose\",\"\"), ['car', 'football'], {2: 'b'}),\n",
    "    ((\"Robert\",\"\",\"Williams\"), ['box', 'music'], {3: 'c'})\n",
    "  ]\n",
    "\n",
    "df3 = spark.createDataFrame(data=structureData,schema=arrayStructureSchema)\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_P75crVkoVP",
    "outputId": "ee80f1be-c629-4adb-fc21-f797bcc30eaa"
   },
   "outputs": [],
   "source": [
    "df3.filter(array_contains(df3.hobbies,\"football\")) \\\n",
    "    .show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7wIBH1plh4D"
   },
   "source": [
    "**Сортировка**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eid2Pim6oYdE"
   },
   "source": [
    "сделаем еще фильтрацию, чтобы увидеть резульат (orderBy тут аналог)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BY_-oj2mjs6",
    "outputId": "fa77bcb8-3114-40c3-88f6-9881d7f5aa2f"
   },
   "outputs": [],
   "source": [
    "df.filter(df.userID == 75).sort(df.date_minute, df.rating.desc()).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiqsFj72pkvM"
   },
   "source": [
    "**groupby**\n",
    "\n",
    "Когда мы выполняем groupBy() в PySpark DataFrame, он возвращает объект GroupedData, который содержит следующие агрегатные функции:\n",
    "\n",
    "min(), max(), mean(), count(), sum(), avg(), agg(), pivot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cL6AvkZPoeiy",
    "outputId": "31a31b1b-3c66-4c8f-e7cd-3af65c409d6c"
   },
   "outputs": [],
   "source": [
    "df.groupby('date_year').mean('rating').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QjgENxurJ_t"
   },
   "source": [
    "мы уже умеем применять разные методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvnbA2-aqzXI",
    "outputId": "fe9c2981-ed72-4e53-d13c-91b679167745"
   },
   "outputs": [],
   "source": [
    "df.groupby('date_year')\\\n",
    "  .mean('rating')\\\n",
    "  .sort('date_year')\\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBGHTsSxrUri",
    "outputId": "7b329e72-e46a-4a68-e17a-5b94c6c18608"
   },
   "outputs": [],
   "source": [
    "df.filter(df.rating <= 2)\\\n",
    "  .groupby('date_year')\\\n",
    "  .count()\\\n",
    "  .withColumnRenamed('count', 'number')\\\n",
    "  .sort('date_year')\\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_8epVoOrwG3"
   },
   "source": [
    "несколько колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SIzk9xOrsec",
    "outputId": "95dc57df-e749-4fa1-d57a-32cca9b39fbf"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"date_year\", \"date_month\") \\\n",
    "  .mean(\"rating\", \"userID\") \\\n",
    "  .sort('date_year', 'date_month') \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq4SNRAkukI2"
   },
   "source": [
    "Для того, чтобы делать несколько разных агрегаций и еще менять сразу имя столбца нужно немного изменить синтаксис"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ABwr_y5ugQi"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, mean, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OrMJN9ttWYQ",
    "outputId": "66403168-e23a-4209-a1fa-c4a45c7185ab"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"date_year\") \\\n",
    "    .agg(min(\"rating\").alias(\"min_rating\"), \\\n",
    "         mean(\"rating\").alias(\"mean_rating\"), \\\n",
    "         max(\"rating\").alias(\"max_rating\")\n",
    "         ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahpMujLmcI1n"
   },
   "source": [
    "Еще можно сделать pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9J-VoOc0cWTd",
    "outputId": "7f6b303f-b5f2-422e-ec03-fa990df84dc1"
   },
   "outputs": [],
   "source": [
    "df.groupBy('date_year')\\\n",
    "  .pivot('date_month')\\\n",
    "  .mean('rating')\\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0Xl9vFCu_eK"
   },
   "source": [
    "**Join's**\n",
    "\n",
    "Куда же без них. Что есть: INNER, LEFT OUTER, RIGHT OUTER, LEFT ANTI, LEFT SEMI, CROSS, SELF JOIN\n",
    "\n",
    "Благодаря оптимизации в датафреймах уже все хорошо работает, спасибо catalist, но чудеса не вечны и плохой код/незнание данных все равно даст о себе знать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YneaY-MDxca7"
   },
   "source": [
    "Сделаем для себя несколько таблиц, чтобы можно было экспериментировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Jrab0pMxbJp"
   },
   "outputs": [],
   "source": [
    "df_mean_user_rating = df.groupBy(\"userID\")\\\n",
    "                        .mean('rating')\\\n",
    "                        .withColumnRenamed('avg(rating)', 'avg_rating_all')\n",
    "\n",
    "df_mean_user_rating_year = df.groupby('userID', 'date_year')\\\n",
    "                             .mean('rating')\\\n",
    "                             .withColumnRenamed('avg(rating)', 'avg_rating_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOArojkkxHR0",
    "outputId": "9d221dc6-824e-4cbe-c317-6ec3caf269d8"
   },
   "outputs": [],
   "source": [
    "df_mean_user_rating.printSchema()\n",
    "\n",
    "df_mean_user_rating_year.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xejW3UuRzb0g"
   },
   "source": [
    "И давайте все в 1 блоке кода, чтобы не растягивать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "sCpt6PH4zhGh",
    "outputId": "089da077-a775-45e3-f33e-b3a8c4156d81"
   },
   "outputs": [],
   "source": [
    "df.join(df_mean_user_rating, on=df.userID == df_mean_user_rating.userID, how='inner')\\\n",
    "  .join(df_mean_user_rating_year, on=[df.userID == df_mean_user_rating_year.userID,\n",
    "                                      df.date_year == df_mean_user_rating_year.date_year],\n",
    "        how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12j__QNvZa5v"
   },
   "source": [
    "Надо удалить дублирующиеся столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNOXJ1Trwkmt"
   },
   "outputs": [],
   "source": [
    "res_join = df.alias('t').join(df_mean_user_rating.alias('t1'), on=col('t.userID') == col('t1.userID'), how='inner')\\\n",
    "  .drop(col('t1.userID'))\\\n",
    "  .join(df_mean_user_rating_year.alias('t2'), on=[col('t.userID') == col('t2.userID'),\n",
    "                                      col('t.date_year') == col('t2.date_year')],\n",
    "        how='inner')\\\n",
    "  .drop(col('t2.userID'))\\\n",
    "  .drop(col('t2.date_year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SFHiwk3bjar",
    "outputId": "68e5cca4-83cc-4a45-c98e-55545a6ed694"
   },
   "outputs": [],
   "source": [
    "res_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5AnHARphOdO"
   },
   "source": [
    "**union и unionAll**\n",
    "\n",
    "Используются для объединения датафреймов с одинаковой структурой, используется union, так как unionAll с версии 2.0.0 более не используется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUT2BY-Mh9mD"
   },
   "outputs": [],
   "source": [
    "df1 = df.filter(df.date_year == 2006)\n",
    "df2 = df.filter(df.date_year != 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAlbx9vNiJfl",
    "outputId": "0560d7eb-7075-461c-b74f-3a2b02f6b1e0"
   },
   "outputs": [],
   "source": [
    "union_df = df1.union(df2)\n",
    "\n",
    "print(df.count(), union_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHSH3q7tixKe"
   },
   "source": [
    "Desclaimer: все по sql, надеюсь, помнят разницу между union и union all, когда union убирает дубликаты. Так вот pyspark ничего не удаляет, убрать дубликаты можно только через drop_duplicates, distinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6i0lcIVAj7XS"
   },
   "source": [
    "Также при union pyspark делает объединение по столбцам as is, не пытаясь понять, что в одном датафрейме нужный стобец на 1 позиции, а в другом он на 5. Для этого с версии 3.1 есть замечательный метод unionByName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwiOqXPolaNz"
   },
   "source": [
    "**UDF - user defined functions**\n",
    "\n",
    "из курса про rdd помним про map, тут тоже можно перегнать все в rdd и делать map, но можно и через udf. Стоит отметить, что при этом мы теряем возможность оптимизации и произодительность в dataframe, так как udf - black box для спарка.\n",
    "\n",
    "Но зато эти функции переиспользуемы и их можно применять в sql запросах, как те же udf в oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lk5nXLrEiqPa"
   },
   "outputs": [],
   "source": [
    "def udf_example(rating):\n",
    "    rating = rating * 20\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkUtKFLM2BGT"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DK2Brnu2LSl"
   },
   "outputs": [],
   "source": [
    "my_udf = udf(lambda x: udf_example(x), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_I485a32XFD",
    "outputId": "ef13b887-c86a-4593-c843-eb73c5fd2072"
   },
   "outputs": [],
   "source": [
    "df.select(['userID', 'movieID', 'rating'])\\\n",
    "  .withColumn('rating_100', my_udf(col('rating')))\\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwrlR5GI3dxB"
   },
   "source": [
    "Для тех, кто любит декораторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaNfPZdg3dBs"
   },
   "outputs": [],
   "source": [
    "@udf(returnType=DoubleType()) \n",
    "def udf_example_decorator(rating):\n",
    "    rating = rating * 20\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnFY-jHV3qph",
    "outputId": "30d1233d-1cb9-44ea-a19c-8c41b84b3ade"
   },
   "outputs": [],
   "source": [
    "df.select(['userID', 'movieID', 'rating'])\\\n",
    "  .withColumn('rating_100', udf_example_decorator(col('rating')))\\\n",
    "  .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLtZleE74gdv"
   },
   "source": [
    "Зарегистрируем функцию для будущих примеров с sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8QOkBZY4k-q",
    "outputId": "4da4e716-94fd-4e29-f263-ba84b7b678b5"
   },
   "outputs": [],
   "source": [
    "spark.udf.register(\"udf_example_decorator\", udf_example_decorator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P_NIuglWV72"
   },
   "source": [
    "**SQL**\n",
    "\n",
    "Ну раз уж пошла такая тема, давайте рассмотрим, как можно сделать все при помощи любимого SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3KC55x4XCET"
   },
   "source": [
    "можно делать TempView и GlodalTempView, отличие в том, что обычный view будет жить, пока жива сессия спрака, а глобальная, пока жив sparkcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zn1xgFFa5Fr1"
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7USYu6N142hn",
    "outputId": "c16cbf48-bd3d-41ee-9fc5-c47108b8553e"
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select userID, movieID, rating, udf_example_decorator(rating) as rating_100\n",
    "from\n",
    "df\n",
    "'''\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNdTc07RWlLd"
   },
   "source": [
    "Ну и наш join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXqOTAhHWkQ1"
   },
   "outputs": [],
   "source": [
    "df_mean_user_rating.createOrReplaceTempView('df_mean_user_rating')\n",
    "df_mean_user_rating_year.createOrReplaceTempView('df_mean_user_rating_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "slhrZnkeXgdo",
    "outputId": "810f5c6e-76c3-4671-ea22-615e0f40148d"
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select t.*, t1.avg_rating_all, t2.avg_rating_year\n",
    "from\n",
    "df t, df_mean_user_rating t1, df_mean_user_rating_year t2\n",
    "where\n",
    "    t.userID = t1.userID and\n",
    "    t.userID = t2.userID and\n",
    "    t.date_year = t2.date_year\n",
    "'''\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUh-iswqZLFy"
   },
   "source": [
    "**fill() и fillna()**\n",
    "\n",
    "Оба метода идентичны, заполняют пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqDjntPTaMWK"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zu7pS9UVZKcY"
   },
   "outputs": [],
   "source": [
    "data2 = [(2,\"Michael Rose\"),(3,\"Robert Williams\"),\n",
    "     (4,\"Rames Rose\"),(5, None), (6, None),\n",
    "     (None, 'Fred Tf')\n",
    "  ]\n",
    "df2 = spark.createDataFrame(data2, ['id', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jtEyGTDFkPu"
   },
   "source": [
    "А где пропуски?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEQhiI-FFiLe",
    "outputId": "080662b1-5684-4777-a2e9-93393aa8d285"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "df2.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df2.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwL5c9f1aZfQ",
    "outputId": "81c5dc5f-86d8-4533-cc41-fd8cf51f0d9d"
   },
   "outputs": [],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4ZY2Y9Lab8D",
    "outputId": "b6e96b06-5992-40d5-f67f-2b98595d1aa6"
   },
   "outputs": [],
   "source": [
    "df2.fillna({'id': 0}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vyi4vYFSa_TS",
    "outputId": "3488df19-6b3b-408e-e7cb-b09e1f97ded0"
   },
   "outputs": [],
   "source": [
    "df2.fillna({'id': 0, 'name': 'Unknown'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFF3UQJlbJsY"
   },
   "source": [
    "Аналогично"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjH5G5DCbMJG",
    "outputId": "e2e41bf8-9956-44eb-e282-b604a4f11211"
   },
   "outputs": [],
   "source": [
    "df2.na.fill({'id': 0, 'name': 'Unknown'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAVfOjcTcdGQ"
   },
   "source": [
    "**Домашнее задание**\n",
    "\n",
    "Куда же без домашки, верно?\n",
    "\n",
    "Есть данные по транзакциям клиентов, ваша задача состоит в анализе этих данных и подготовки к структуре, которая похожа на ту структуру, которая сейчас часто нами используется при построении моделей на транзакциях + промежуточные задания.\n",
    "\n",
    "Не забудьте делать всякие show после каждого задания, чтобы было видно результат\n",
    "\n",
    "Файл spark_transactions.parquet можете забрать в папке с записями лекций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMeEjuq7H6tx"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-0T0sTY5Odw"
   },
   "outputs": [],
   "source": [
    "trans_data = spark.read.parquet('spark_transactions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTg-84Tr7tq4",
    "outputId": "3c5c1e19-9abc-491a-bc28-8dda8b27e7ed"
   },
   "outputs": [],
   "source": [
    "trans_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wa1YHO4iJNlU"
   },
   "source": [
    "Посмотрим на схему данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfi4rGq8IP70"
   },
   "source": [
    "Сколько транзакций у пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ65xaaxGfyZ"
   },
   "source": [
    "Сколько карт у пользователей в среднем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ5tOK9AJMbJ"
   },
   "source": [
    "Немного обработаем данные: Amount в float, из Time вытянем час транзакции и удалим исходный Time, Zip  к типу int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Km4bInOzTf2d"
   },
   "source": [
    "Посчитайте количество транзакций по годам, учитывая только те транзакции, объем которых был больше 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPQ3E9SGDtWJ"
   },
   "source": [
    "Определите, есть ли пропуски в данных по каждому столбцу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg3ZKFXYGF1I"
   },
   "source": [
    "Заполните пропуски исходя из типа данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkiD1y5xGfet"
   },
   "source": [
    "Теперь самое время сгруппировать данные по каждому клиенту (можно использовать collect_list для сбора данных после агрегации)\n",
    "Когда будете делать агрегацию, то возьмите только чать выборки, например, у кого User <= 10, для всей выборки либо не хватит памяти, либо очень долго считать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pyspark_DataFrame.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
