{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EAL7YbIqGFr"
      },
      "source": [
        "**Занятие первое**\n",
        "\n",
        "Начнем с простого. Многие знают что такое map и reduce операции, но все же для закрпеления мы их тут реализуем. Ах да, не забудем и про shuffle. Делать все будем на упрощенной задаче с word count для ознакомления с самим подходом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DBUYlacS6nb"
      },
      "source": [
        "На самом деле мы рассмптрим все в упрощенном виде, но это даст нам понимание, как можно через hadoop streaming, например, писать самописные map и reduce операции"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHxuTfZ1TKc9"
      },
      "source": [
        "! mapred streaming \\\n",
        "  -input /wiki/sample.jsonl \\\n",
        "  -output /word-count \\\n",
        "  -mapper \"/opt/conda/bin/python3.6 mapper.py\" \\\n",
        "  -reducer \"/opt/conda/bin/python3.6 reducer.py\" \\\n",
        "  -file mapper.py \\\n",
        "  -file reducer.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe2aSFz_Tgqv"
      },
      "source": [
        "Выше mapper.py и reducer.py это программы, которые выполняют одноименные операции нам потоком информации из jsonl файла, записывая ответ в файл word-count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hGAAKrdu5d-",
        "outputId": "4b809607-78be-46e7-ab1d-4a7a51234c68"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re \n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPXzd-YMtqcO"
      },
      "source": [
        "Давайте загрузим файл с текстом и посмотрим на него"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKUCkYpBp9Lt"
      },
      "outputs": [],
      "source": [
        "with open('spark_text.txt', 'rb') as f:\n",
        "    data = f.readlines()\n",
        "data = [text.decode() for text in data if text.decode() != '\\r\\n']    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CywPTchftnqK",
        "outputId": "2fc8835f-de9d-4f22-85d1-e4425d4f22a8"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydjOU0HLwCZq"
      },
      "source": [
        "Как бы мы сделали..\n",
        "Надо немного почистить слова, а также сделать все в парадигме MapReduce. Понятно, что можно все написать проще, но мы ведь хотим понять, как это работает=)\n",
        "\n",
        "Загрузим стоп слова, очистим от них текст, приведем к нижнему регистру, всем раздадим ключи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-zIUslxxtyQ"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stop_words = set(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOXxYSKI2EfQ",
        "outputId": "a039dff2-3238-45a1-c499-cbf433154974"
      },
      "outputs": [],
      "source": [
        "stop_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDK6W4MUewdv"
      },
      "source": [
        "пунктуацию тоже полезно бы удалить"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "XhrSCeUJ2MKZ",
        "outputId": "62be28c9-e3bc-4a50-c5b5-afb013a8719a"
      },
      "outputs": [],
      "source": [
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0AjYtsiv9tc"
      },
      "outputs": [],
      "source": [
        "def mapper_text(text):\n",
        "    clean_text = re.sub(rf\"[{string.punctuation}]\", \"\", text)\n",
        "    words = nltk.word_tokenize(clean_text)\n",
        "    words_with_value = [(word.lower(), 1) for word in words \n",
        "                        if word not in stop_words]\n",
        "    words_with_value = sorted(words_with_value, key=lambda x:x[0])\n",
        "    return words_with_value\n",
        "\n",
        "def create_chunks(shuffled_data):\n",
        "    result = {}\n",
        "    for idx, data in shuffled_data:\n",
        "        if idx in result:\n",
        "            result[idx].append(data)\n",
        "        else:\n",
        "            result[idx] = [data]\n",
        "    return list(result.items())\n",
        "\n",
        "def shuffle_text(mapper_result, n_nodes=5):\n",
        "    shuffled_data = []\n",
        "    for key, value in mapper_result:\n",
        "        shuffled_data.append((hash(key)%n_nodes, (key, value)))\n",
        "    shuffled_data = sorted(shuffled_data, key=lambda x: x[0])\n",
        "    chunks = create_chunks(shuffled_data)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# на самом деле для reduce в жизни пишут иначе..не зря мы сортируем внутри map\n",
        "#данные по ключам. Это нужно для избавления от этапа проверки ключа и поиска\n",
        "def reduce_text(values_to_reduce):\n",
        "    result = {}\n",
        "    for key, value in values_to_reduce:\n",
        "        if key in result:\n",
        "            result[key] += 1\n",
        "        else:\n",
        "            result[key] = 1\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7qztZ0ijcqf"
      },
      "source": [
        "Проверим, что все работает\n",
        "\n",
        "Сначала map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpqqPnNRhCXp"
      },
      "outputs": [],
      "source": [
        "map_stage = mapper_text(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hiOXuxSsDno",
        "outputId": "b4261950-941e-42b2-c6bf-826000e044f8"
      },
      "outputs": [],
      "source": [
        "map_stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoOq2kxGl4FM"
      },
      "source": [
        "shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLyQcJ7Xjmll"
      },
      "outputs": [],
      "source": [
        "shuffle_stage = shuffle_text(map_stage, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig2vthBFsNTm",
        "outputId": "7520831a-d8f5-4f23-9985-4cf3210fe83e"
      },
      "outputs": [],
      "source": [
        "shuffle_stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rqyNgzpl8q1"
      },
      "source": [
        "reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJed4iQsll9i",
        "outputId": "346bd3cc-60f8-4ecc-cb89-54db38626479"
      },
      "outputs": [],
      "source": [
        "reduce_text(shuffle_stage[4][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOuqRbx5srNh"
      },
      "source": [
        "Итак, осталось все рассчитать параллельно и собрать результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NgoQwpasxwq"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3ogNEUhtvkD"
      },
      "outputs": [],
      "source": [
        "n_nodes = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rA9awfQ4RSo"
      },
      "source": [
        "Обернем в 1 функциию для удобства map и shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TItZtKEF4Qiu"
      },
      "outputs": [],
      "source": [
        "def map_shuffle(text, n_nodes):\n",
        "    map_result = mapper_text(text)\n",
        "    shuffle_result = shuffle_text(map_result, n_nodes)\n",
        "    return shuffle_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WOywHRItFWD",
        "outputId": "d563a36b-2688-4f69-e9f0-e2935fa7d432"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
        "    res = parallel(delayed(map_shuffle)(df, n_nodes) for df in data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvAYM5vA9K8N"
      },
      "source": [
        "Сделаем что-то вроде перессылки, собирая все в словари и заодно посмотрим на сколько равномерно распределлиись наши слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kTLnBO24013"
      },
      "outputs": [],
      "source": [
        "shuffle_stage = {i:[] for i in range(5)}\n",
        "for values in res:\n",
        "    values = dict(values)\n",
        "    for key in values.keys():\n",
        "        shuffle_stage[key].extend(values[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9sAjyP46kUE",
        "outputId": "48574b79-eba6-4542-de4f-26eb12e17bc2"
      },
      "outputs": [],
      "source": [
        "for key in shuffle_stage.keys():\n",
        "    print(f'{key}: number of words = {len(shuffle_stage[key])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVEA-LZG9eEv"
      },
      "source": [
        "И последний этап - нужно сделать reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i95b8FbDboX",
        "outputId": "ce21344f-88b7-4b18-d1b0-93c7fac77c3c"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
        "    res = parallel(delayed(reduce_text)(shuffle_stage[key]) for key in shuffle_stage.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZsgvg9oEVwt"
      },
      "source": [
        "Собираем результат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVKdO8eAD24r"
      },
      "outputs": [],
      "source": [
        "result = {}\n",
        "for partition in res:\n",
        "    for key in partition.keys():\n",
        "        if key in result:\n",
        "            result[key] += partition[key]\n",
        "        else:\n",
        "            result[key] = partition[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUTsOJf7EtW1",
        "outputId": "3c519dc0-0065-4981-b5c2-7633342208cc"
      },
      "outputs": [],
      "source": [
        "sorted(result.items(), key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OViND9SFFTOd"
      },
      "source": [
        "Да, было бы проще все сделать иным кодом и в один проход, но целью было разобрать, как все это примерно работает под капотом на больших данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhK08F7hFjv_"
      },
      "source": [
        "**Домашнее задание**\n",
        "\n",
        "Посчитать количество рейтингов больше 4 для каждого фильма и вывести фильмы в порядке убывания количества этих оценок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPx9_0-wFlK-"
      },
      "outputs": [],
      "source": [
        "with open('user_ratedmovies.dat', 'rb') as f:\n",
        "    data = f.readlines()\n",
        "headers = data[0].decode().split('\\t')[:3]\n",
        "data = [row.decode().split('\\t')[:3] for row in data[1:]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8yWQm0zJegy",
        "outputId": "947e43ba-846b-4c72-ac2a-ebcdf089436d"
      },
      "outputs": [],
      "source": [
        "headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgDpQdAeRG5e",
        "outputId": "3ea731fc-6330-4540-b419-9b9cacb2b48f"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln4GFhQZH5tM",
        "outputId": "b198956e-4cff-4db7-cb9f-f18b9dd7827c"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzkqhk9MRL8P"
      },
      "source": [
        "Shuffle делать не нужно, он работает сам \"под копотом\". Пишем только map и reduce + параллелим вычисления. Лучше задавать batch_size при распараллеливании, либо даже заранее все разбить на батчи для обучения, будет быстрее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1aUiwrJRK3W"
      },
      "outputs": [],
      "source": [
        "def map_rating(row):\n",
        "    pass\n",
        "\n",
        "def reduce_rating(map_row):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJdLsomDRyS0"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10) as parallel:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmKhm2eeRyVZ"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10) as parallel:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed0nAHrDSMcX"
      },
      "source": [
        "После reduce все можно собрать в одном цикле, считаем, что данные переслали после на 1 машину и агрегируем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ukq4eiUKSJhq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Spark_lesson1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
